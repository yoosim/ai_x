[머신러닝]
▶ 머신러닝 개요 
   insight 도출 : 탐색적 자료분석(EDM) : Pandas&Numpy,matplotlib&seaborn
   optimiaztion : 머신러닝(sk-learn, scipy.stats, statsmodels)과 딥러닝(tensorflow)

   머신러닝 : 학습을 통해 측정된 작성 성능을 향상
	- 지도 학습(감독 학습, 슈퍼바이저 러닝) : 독립변수, 타겟변수 있음
	- 비지도 학습(자율학습) : 타겟변수 없음. k-means,PCA 

▶ 데이터 탐색
   1)변수의 종류
      데이터 속성에 따라 명목식(남,여), 순서식(서열, 5점척도), 구간식(순서, 간격의미),비율식(연속형, 영존재)으로 데이터 구분
	- 명목식 : 서로다른 범주를 구분하는 변수
	- 순서식 : 순서(서열)이 있음
	- 구간식 : 숫자간 간격은 일정하지만 절대적인 0이 없음. 비율 비교 불가
	- 비율식 : 절대적인 0이 존재 : "없음"의 의미 / 비율 비교 가능
      변수의 타입에 따라 연속형, 이산형(라벨인코딩), 범주형
	- 연속형:연속적인 수치
	- 이산형:셀이 수로 셀 수 있는 값들
	- 범주형:숫자가 아닌 카테고리 형태
      데이터 품질에 따라 특이값(비정상치, 이상치), 결측값

   2) 통계요약 : 중심 위치 측도(평균, 중앙값=중위수, 최빈값), 산포측도(왜도,첨도)
      분포도(히스토그램)
      왜도(ske) : 0(대칭), 음수(왼쪽으로 긴꼬리 분포=오른쪽으로 치우친 분포), 양수(오른쪽으로 긴꼬리 분포)
      첨도(kurtosis) : 뾰족한 정도

   3) 기초 통계량
      describe() 함수
	- 수치형 : 최소값, 최대값, 사분위수, 평균, 표준편차
	- 범주형 : unique갯수, 최빈데이터, 최빈데이터빈도
	   *범주형인지 체크하는건 info를 통해 object가 나오면 범주형

   4) 데이터 가속화 
      설치>>pip install dataprep : EDA를 쉽게 lib 
      *dataprep.eda안의 주요함수
	- plot() : 각 변수의 분포 그래프, 파이그래프, 산점도 등 표시
	- plot_correlation() : 각 변수들 사이의 상관계수 히트맵
	- plot_missing() : 결측값 분포를 쉽게 확인하는 그래프

   5) 상관분석 : 두 변수간의 선형적 관계가 있는지 분석
	: 공분산, 상관계수 (-1~1)
	: 피어슨 상관계수 (Pearson correlation coefficient)
	① 두 변수가 모두 연속형 자료 일 때, 두 변수간 선형적인 상관관계의 크기를 나타냄
	② -1:반비례, 1: 비례 / 원인-결과는 아니고 상관관계만
	③ 일반적으로 0.6이상이면 양의 상관관계, -0.6이하면 음의 상관관계
	: 스피어만 상관계수 : 두 변수가 순서식(ex.5점 척도)이거나 두 연속형 데이터의 분포가 심각하게 정규분포를 벗어난 경우

   6) 독립성 검증 : 두 변수간의 관계를 통계적으로 유의미한지 검증 
	: 피서의 검정 -> 데이터 수가 적을 때
	: 맥니마 검정 -> 치료효과 등 대조군과 비교하기 위해
	: 다차원척도법 -> 어떤 변수들이 연관성이 높은지 시각화 

▶ 데이터 전처리  : 데이터 스케일조정, 인코딩, 결측치 처리 
   1) 데이터 스케일 조정 : 학습효과 높이기 위해서 진행
	- fit(data)
	- transfoorm(data)
	- fit_transform(data)
	- inverse_transform(data) - Normalizer는 없음

   2) 정규화와 표준화에 대한 정리
	*정규화
	   - 스케일링시 최대,최소값이 사용
	   - 피쳐의 크기가 다를 때 사용 
	   - (0,1) 또는 (-1,1)사이의 값으로 스케일링
	   - 분포에 대해 모를 때 유용
	   - MinMaxScaler, Normalizer
	* 표준화
	   - 스케일링 시 평균과 표준편차가 사용
	   - 평균이 0, 표준편차가 1로 스케일링
	   - 특정 범위로 제한되지 않는다
	   - 피처가 정규분포인 경우 유용
	   - StandardScaler, RobustScaler

	<Scaler 종류에 대한 내용 정리>
	* StandardScaler
	   - 적용방식 : Z-score 정규화
	   - 수식 : X−μ / σ	
	   - 특징 : 평균0, 표준편차1로 변환	
	   - 이상치영향 : 민감
	   - 상황 : 정규분포가정모델(회귀, PCA, SVM)

	* MinMaxScaler
	   - 적용방식 : 최소-최대 정규화	
	   - 수식 : X−Xmin / (Xmax−Xmin)
	   - 특징 : 0~1 범위로 변환	
	   - 이상치영향 : 많이민감	
	   - 상황 : 이상치가 많은 경우

	*RobustScaler
	   - 적용방식 : 중앙값 기준 스케일링		
	   - 수식 : X-Q1/ (Q3-Q1)	
	   - 특징 : 0~1 이상치 영향을 덜 받음		
	   - 이상치영향 : 적음
	   - 상황 : 값을 0~1로 조정해야 하는 경우 안정적으로 변환

	*Normalizer
	   - 적용방식 : 벡터 정규화 (L2, L1)		
	   - 수식 : x/||X||	
	   - 특징 : 각 샘플의 크기를 1로 맞춤(행 단위로 정규화)		
	   - 이상치영향 : 없음
	   - 상황 : 거리기반 모델, KNN, Cosine Similarity, NLP

	*데이터 전처리 과정 
	   - 데이터 수집 → 데이터 전처리(비지도 학습포함) →모델 구축(DL,ML) → 성능평가 → 배포유지보수
		: 데이터품질이 높으면 데이터전처리를 단축
		: 결측치처리, 표준화 및 정규화, 인코딩(원핫인코딩,라벨인코딩), 오타수정, 단어통일, 고유명사정리, 수치데이터 단위 통일

   3) 인코딩
       *레이블 인코딩 
	- 실제값과 상관없는 0 ~ k-1 사이의 정수로 변환

       *원핫인코딩 
	- sklearn.preprocessing.OneHotEncoder : 2차원 정수나 문자데이터
	- sklearn.preprocessing.LabelBinarizer : 1,2차원 정수데이터
	- tensorflow.keras.utils.to_categorical : 1차원 정수데이터
	- pd.get_dummeies : 1차원 정수나 문자데이터
       
       *평균값 인코딩 
	- 장점 : 차원에 억압받지않고 빠른 학습 가능 / 회귀분석뿐만 아니라 분류분석에서도 예측값에 좀 더 가깝게 학습
	- 단점 : 과적합(학습셋에 대하여 예측을 잘 함)
   4) 결측값 처리 
	- 대체 : fillna()함수, sklearn.impute.SimpleInputer
	          > mean(평균값 대체) / median(중앙값 대치) / most_frequent(최빈값 대체) / fillna(method='bfill')(다음행 값으로 대체) / fillna(method='ffill')(이전행 값으로 대체)
	- 제거(결측치가 20% 이상일때)
	* 결측치 생성 : float('nan') = np.nan